{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from Method import * \n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import ast\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag_of_words\n",
    "def BoW(data, col):\n",
    "    '''Return a Vectorizing document using Bag of Words'''\n",
    "    dictionary = corpora.Dictionary(data[col])\n",
    "    doc_term_matrix = [dictionary.doc2bow(rev) for rev in data[col]]\n",
    "    return doc_term_matrix,dictionary\n",
    "\n",
    "# TF - IDF\n",
    "def tfidf(data, col):\n",
    "    '''Return a Vectorizing document using TF IDF'''\n",
    "    text_strings = [' '.join(tokens) for tokens in data[col]]\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_dtm = tfidf_vectorizer.fit_transform(text_strings)\n",
    "    # Convert the TF-IDF weighted DTM to a gensim corpus\n",
    "    corpus = gensim.matutils.Sparse2Corpus(tfidf_dtm, documents_columns=False)\n",
    "\n",
    "    # Create a dictionary mapping terms to their integer ids\n",
    "    id2word = dict((v, k) for k, v in tfidf_vectorizer.vocabulary_.items())\n",
    "    return corpus, id2word\n",
    "\n",
    "\n",
    "# Word2Vec\n",
    "def Word2Vec_method(data, col):\n",
    "    model = Word2Vec(sentences=data[col], vector_size=100, window=5, min_count=1, workers=4)\n",
    "    \n",
    "    # Initialize an array to store document vectors\n",
    "    document_vectors = []\n",
    "    \n",
    "    # Iterate over each document\n",
    "    for sentence_tokens in data[col]:\n",
    "        # Initialize an array to store word vectors for the current document\n",
    "        word_vectors = []\n",
    "        \n",
    "        # Iterate over each token in the current document\n",
    "        for token in sentence_tokens:\n",
    "            if token in model.wv:\n",
    "                word_vectors.append(model.wv[token])\n",
    "        \n",
    "        # If there are word vectors for the current document, compute the average and append it to document_vectors\n",
    "        if word_vectors:\n",
    "            document_vector = np.mean(word_vectors, axis=0)  # Compute the average word vector\n",
    "            document_vectors.append(document_vector)\n",
    "        else:\n",
    "            # If no word vectors are found for the current document, append a zero vector\n",
    "            document_vectors.append(np.zeros(model.vector_size))\n",
    "        # Flatten the list of vectors\n",
    "        flat_vectors = [vector for sublist in document_vectors for vector in sublist]\n",
    "    return flat_vectors\n",
    "\n",
    "# Bertmodel\n",
    "def Bertmodel(data, col):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Num_words_text</th>\n",
       "      <th>Text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231516</td>\n",
       "      <td>B005OOGTBQ</td>\n",
       "      <td>A2SUIKWQTSO3GG</td>\n",
       "      <td>Peter Harrison</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1338163200</td>\n",
       "      <td>WAAY overpriced compared to local grocery</td>\n",
       "      <td>I love Anna's Ginger Thin cookies, and was hop...</td>\n",
       "      <td>75</td>\n",
       "      <td>[love, anna, ginger, thin, cooky, hoping, find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>384588</td>\n",
       "      <td>B008CTBK7S</td>\n",
       "      <td>A34QMBOSM068W9</td>\n",
       "      <td>Loves to Listen</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1305676800</td>\n",
       "      <td>Love this product but the price is rediculous</td>\n",
       "      <td>Don't buy this chocolate PB2 here. Go to Bell ...</td>\n",
       "      <td>67</td>\n",
       "      <td>[dont, chocolate, bell, plantation, site, four...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId          UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "0  231516  B005OOGTBQ  A2SUIKWQTSO3GG   Peter Harrison                     0   \n",
       "1  384588  B008CTBK7S  A34QMBOSM068W9  Loves to Listen                     3   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time  \\\n",
       "0                       0      1  1338163200   \n",
       "1                       8      1  1305676800   \n",
       "\n",
       "                                         Summary  \\\n",
       "0      WAAY overpriced compared to local grocery   \n",
       "1  Love this product but the price is rediculous   \n",
       "\n",
       "                                                Text  Num_words_text  \\\n",
       "0  I love Anna's Ginger Thin cookies, and was hop...              75   \n",
       "1  Don't buy this chocolate PB2 here. Go to Bell ...              67   \n",
       "\n",
       "                                      Text_processed  \n",
       "0  [love, anna, ginger, thin, cooky, hoping, find...  \n",
       "1  [dont, chocolate, bell, plantation, site, four...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1  = pd.read_csv('Processed_data\\data_1.csv', index_col= 0)\n",
    "data_1['Text_processed'] = data_1['Text_processed'].apply(ast.literal_eval)\n",
    "data_1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = BoW(data_1, 'Text_processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF- IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50000x58826 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1647380 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = tfidf(data_1, 'Text_processed')\n",
    "tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
